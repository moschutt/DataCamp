---
title: "Data Camp / ARIMA Modeling with R - Chapter 1"
output:
  pdf_document: default
  html_notebook: default
---

Initialize and load the data

```{r}
library(astsa)
library(xts)
```

Chapter 1 of [Data Camp - ARIMA Modeling with R](https://www.datacamp.com/courses/arima-modeling-with-r)

**Homoscedastic**: If all random variables in a sequence or vector have the same finite variance.  This is also known as **homogeneity of variance**.

Regression: $Y_i = \beta X_i + \epsilon_i$, where $\epsilon_i$ is _white noise_.

**White Noise**:
* indipendant normals with common variance
* basic building block of time series

**AutoRegression**: $X_t = \phi X_{t-1} + \epsilon_t$  

Regress _Today_ on _Yesterday_.    

Where _Today_ is the dependant variable and _Yesterday_ is the independant variable.

Assumption that the errors are correlated and assuming the errors are **not** correlated can lead to bad models.  One way to ensure they are corrolated is to use a **Moving Average**.

**Moving Average**: $\epsilon_t = W_t + \theta W_{t-1}$  ($W_t$ is **white noise**).

Putting these together is the **ARMA** model.

**ARMA**: $X_t = \phi X_{t-1} + W_t + \theta W_{t-1}$

## Get to know your data.

If available use `help()` or `?` to check on the details of the data you will be using.  We will be using _AirPassengers_.

**Note**: the `$` operator in the _djia_ statement is from the _xts_ class.  Without it, the members must be referenced with the format `djia[,'Close']`.  It also returns an xts object and makes a much prettier graph.

```{r}
par(mfrow=c(2,2))
plot(AirPassengers)
plot(djia$Close)
plot(soi)
```

## Stationarity and Nonstationarity

A time series is staionary when it is "stable".

* The mean is constant over time (no trend)
* The corrolation structure remains constant over time.

**Stationarity** means we can estimate by averaging.  e.g. if the mean is constant it can be estimated by $\bar{x}$

Pairs can be used to estimate correlation on different lags:

$(x_1,x_2),(x_2, x_3), ...$ for lag 1

**Random Walk Trend**

Not Stationary, but differenced data **are** stationary.

```{r}
par(mfrow=c(2,1))

plot(globtemp)
plot(diff(globtemp))
```

If you have stationarity around a trend, differencing still works as with the chicken dataset.

```{r}
par(mfrow=c(2,1))
plot(chicken)
plot(diff(chicken))
```

**Nonstationarity in trend and variability**

As with the Johnson and Johnson data.  In this case `log()` can be used to stabilize the variance and `diff()` to introduce stationarity.

```{r}
par(mfrow=c(3,1))
plot(JohnsonJohnson)
plot(log(JohnsonJohnson))
plot(diff(log(JohnsonJohnson)))
```

**_trend stationary_** is when a time series has stationary behavior _around_ a trend.  A simple example is $Y_t = \alpha + \beta t + X_t$ where $X_t$ is stationary.

A differnet model for trend is **Random Walk** which has the form $X_t = X_{t-1} + W_t$ where $W_t$ is _white noise_.  For **Random Walk with drift** a constant is added which will cause the random walk to drit in the direction (positive or negative) of the drift.

In both cases simple _differencing_ (`diff()`) can remove the trend and coorce the data to stationarity.

## More practice and examples detrending

```{r}
par(mfrow = c(2,1))
plot(globtemp) 
plot(diff(globtemp))

par(mfrow = c(2,1))
plot(cmort)
plot(diff(cmort))
```

## Dealing with Trend and Heteroscedasticity

Often a ts is generated with $X_t = (1 - p_t)X_{t-1}$ where $p_t$ is a small percentage change.  For example, interest on a bank account.  $p_t$ is often referred to as the _return_ or _growth rate_ of a ts.

$p_t$ can be approximated with $Y_t = log X_t - log X_{t-1} \approx p_t$ and can be calculated in R with `diff(log(x))`.

By applying the `diff(log(x))` to the dataset you get the _stationary_ de-trended _growth rate_ of the ts.

```{r}
par(mfrow = c(2,1))
plot(gnp)
plot(diff(log(gnp)))

par(mfrow = c(2,1))
plot(djia$Close)
plot(diff(log(djia$Close)))
```

## Stationary Time Series: ARMA

Why is it legal to use ARMA models on Stationary ts?

### Wold Decomposition

Wold showed that **any** stationary ts may be represented as a linear combination of white noise:

$X_t = W_t + a_1 W_{t-1} + a_2 W_{t-2} + ...$

for constants $a_1, a_2, ...$

Any ARMA model has this form, which means they are suited to modeling ts.

**Note**: The special case of MA(q) is already in ths form where constants are 0 after the q-th term.

These can be simulated with `armina.sim()`.

The easiest way to use it is to specify the **model** which is a list with the **order** of the model as c(p, d, q) and the coeficients.  p is the Order of AR, q is the Order of MA and d hasn't been discussed yet.

### Examples

* Create a MA(1) model for $X_t = W_t + 0.9 W_{t-1}$

```{r}
x <- arima.sim(list(order=c(0, 0, 1), ma=0.9), n=100)
plot(x)
```

Plot 100 obs for an AR(2) model  $X_t = -0.9 X_{t-2} + W+t$

Note that since there is no $X_t$ component, it is specified in the _ar=_ member of the model list as 0.

```{r}
set.seed(55)
x = arima.sim(model=list(order=c(2, 0, 0), ar=c(0, -0.9)), n=100)
set.seed(55)
x2 = arima.sim(model=list(order=c(2, 0, 0), ar=c(0.5, -0.9)), n=100)

par(mfrow=c(1, 2))
plot(x)
plot(x2)
```

## More examples

1. White noise
2. MA(1) with parameter 0.9
3. AR(2) with parameters 1.5 and -0.75

```{r}
par(mfrow=c(3,1))
WN <- arima.sim(model=list(order=c(0, 0, 0)), n=100)
plot(WN)

MA <- arima.sim(model=list(order=c(0, 0, 1), ma=0.9), n=100)
plot(MA)

AR <- arima.sim(model=list(order=c(2, 0, 0), ar=c(1.5, (-0.75))), n=100)
plot(AR)
```




